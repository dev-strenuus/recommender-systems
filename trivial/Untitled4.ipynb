{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('input/train.csv')\n",
    "size = df.loc[df['track_id'].idxmax()]['track_id']\n",
    "playlistsForTrack = np.empty([size], dtype=set)\n",
    "for i in range(size):\n",
    "    playlistsForTrack[i] = set(df[df['track_id']==i]['playlist_id'])\n",
    "bestSimilarTracks = sparse.csr_matrix((size, size), dtype=np.double)\n",
    "for i in range(size):\n",
    "    temp = np.zeros((size), dtype=np.int8)\n",
    "    bestSimilarTracks[i][i] = [0,i]\n",
    "    for j in range(i):\n",
    "        den = ((len(playlistsForTrack[i])*1.2)*(len(playlistsForTrack[j]))*0.8)**0.5+5\n",
    "        similarity = len(playlistsForTrack[i] & playlistsForTrack[j])/den\n",
    "        bestSimilarTracks[i][j] = [-1*similarity, j]\n",
    "    for j in range(i+1, size):\n",
    "        den = ((len(playlistsForTrack[i])*1.2)*(len(playlistsForTrack[j]))*0.8)**0.5+5\n",
    "        similarity = len(playlistsForTrack[i] & playlistsForTrack[j])/den\n",
    "        bestSimilarTracks[i][j] = [-1*similarity, j]\n",
    "    #bestSimilarTracks[i] = bestSimilarTracks[i][bestSimilarTracks[i][:,0].argpartition(10)][0:10]\n",
    "    bestSimilarTracks[i] = bestSimilarTracks[i][bestSimilarTracks[i][:,0] !=0]#[:,1]\n",
    "    bestSimilarTracks[i][:,0] = -1*bestSimilarTracks[i][:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "25\n",
      "7550\n",
      "9219\n",
      "9586\n",
      "11660\n",
      "12213\n",
      "15874\n",
      "18259\n",
      "20283\n",
      "23122\n",
      "24183\n",
      "25661\n",
      "27662\n",
      "28160\n",
      "31702\n",
      "33059\n",
      "34400\n",
      "36546\n",
      "37029\n",
      "37400\n",
      "37668\n",
      "38356\n",
      "39839\n",
      "41319\n",
      "42481\n",
      "48513\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, vstack\n",
    "def buildURM():\n",
    "    df = pd.read_csv('input/train.csv')\n",
    "    sizeTracks = df.loc[df['track_id'].idxmax()]['track_id']\n",
    "    sizePlaylists = df.loc[df['playlist_id'].idxmax()]['playlist_id']\n",
    "    URM = csr_matrix((sizeTracks, sizePlaylists), dtype=np.int8)\n",
    "    print(URM)\n",
    "    for i in range(1):\n",
    "        temp = np.zeros((sizePlaylists), dtype=np.int8)\n",
    "        playlistsForTrack = df[df['track_id']==i]['playlist_id']\n",
    "        for playlist in playlistsForTrack:\n",
    "            temp[playlist] = 1\n",
    "            print(playlist)\n",
    "        temp = csr_matrix(temp)\n",
    "        URM = vstack([URM, temp])\n",
    "    return URM\n",
    "URM = buildURM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "row_start = URM.indptr[0]\n",
    "row_end = URM.indptr[1]\n",
    "print(URM.indices[row_start:row_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.05143436328800134, 67],\n",
      "       [0.008053270688703434, 80],\n",
      "       [0.020843232453405268, 89],\n",
      "       [0.021505432064939194, 96]], dtype=object)\n",
      " array([[0.1038421748852724, 15],\n",
      "       [0.03779258897522805, 21],\n",
      "       [0.008054315777311126, 37],\n",
      "       [0.0158421792009815, 42],\n",
      "       [0.0194500343098725, 88]], dtype=object)\n",
      " array([[0.02122248785617707, 19],\n",
      "       [0.009968343088755233, 32],\n",
      "       [0.014006547673450392, 46],\n",
      "       [0.010548547988876052, 75],\n",
      "       [0.02769503474387674, 76]], dtype=object)\n",
      " ... None None None]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix, vstack\n",
    ">>> A = coo_matrix([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(a, b):\n",
    "    contentSimilarity = pd.read_csv('similarity/content.csv')\n",
    "    cbfSimilarity = pd.read_csv('similarity/cbf.csv')\n",
    "    hybridMatrix = a*contentSimilarity + b*cbfSimilarity\n",
    "    return hybridMatrix\n",
    "bestSimilarTracks = merge(0.3, 0.7)\n",
    "df1 = pd.read_csv('input/target_playlists.csv')\n",
    "playlists = np.array(df1['playlist_id'])\n",
    "import random\n",
    "submission = np.empty((len(playlists),2), dtype=object)\n",
    "cont = -1\n",
    "for playlist in playlists:\n",
    "    cont = cont + 1\n",
    "    tracks = np.array(df[df['playlist_id']==playlist]['track_id'])\n",
    "    submission[cont][0] = playlist\n",
    "    tracksSet = set(tracks)\n",
    "    best = {}\n",
    "    temp = 1\n",
    "    for track in tracks:\n",
    "        if cont < 5000:\n",
    "            temp -= 1/(len(tracks)+1)\n",
    "        row_start = bestSimilarTracks.indptr[track]\n",
    "        row_end = bestSimilarTracks.indptr[track+1]\n",
    "        similarTracks = bestSimilarTracks.indices[row_start:row_end]\n",
    "        similarityValues = bestSimilarTracks.data[row_start:row_end]\n",
    "        for i in range(0, len(similarTracks)):\n",
    "            if not similarTracks[i] in tracksSet:\n",
    "                if similarTracks[i] in best:\n",
    "                    best[similarTracks[i]]=best[similarTracks[i]]-similarityValues[i]*temp\n",
    "                else:\n",
    "                    best[similarTracks[i]]=-1*similarityValues[i]*temp\n",
    "    preSorted = [[v, k] for k,v in best.items()]\n",
    "    best = np.empty((max(11,len(preSorted)), 2), dtype=object)\n",
    "    for i in range(len(preSorted)):\n",
    "        best[i] = preSorted[i]\n",
    "    if len(preSorted) < 11:\n",
    "        for i in range(len(preSorted), 11):\n",
    "            best[i] = [0, random.randint(0, 20000)]\n",
    "        print(best)\n",
    "    best = best[best[:,0].argpartition(10)][0:10]\n",
    "    best = best[best[:,0].argsort()][:,1]\n",
    "    best = str(best)\n",
    "    submission[cont][1] = best[1:len(best)-1]\n",
    "df2 = pd.DataFrame(submission, columns=['playlist_id','track_ids'])\n",
    "df2.to_csv('something.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('input/target_playlists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sps\n",
    "import numpy as np\n",
    "c = np.empty(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse as sps\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, normalize\n",
    "from sklearn import feature_extraction\n",
    "\n",
    "\n",
    "class Builder(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train= pd.read_csv('input/train.csv')\n",
    "        self.target_playlists = pd.read_csv('input/target_playlists.csv')\n",
    "        self.tracks = pd.read_csv('input/tracks.csv')\n",
    "        self.playlists = self.get_playlists()\n",
    "        self.tracks_inside_playlists_train = np.empty((len(self.playlists)), dtype=object)\n",
    "\n",
    "    def get_train_pd(self):\n",
    "        return self.train\n",
    "\n",
    "    def get_target_playlists_pd(self):\n",
    "        return self.target_playlists\n",
    "\n",
    "    def get_tracks_pd(self):\n",
    "        return self.tracks\n",
    "\n",
    "    def get_ordered_target_playlists(self):\n",
    "        return np.array(self.target_playlists['playlist_id'])[0:5000]\n",
    "\n",
    "    def get_unordered_target_playlists(self):\n",
    "        return np.array(self.target_playlists['playlist_id'])[5000:]\n",
    "\n",
    "    def get_tracks_inside_playlist_train(self, playlist):\n",
    "        return self.tracks_inside_playlists_train[playlist]\n",
    "    \n",
    "    \n",
    "    def train_test_holdout(self, train_perc):\n",
    "        playlistsSize = len(self.get_playlists())\n",
    "        tracksSize = len(self.get_tracks())\n",
    "        target_playlists = self.get_target_playlists()\n",
    "        cont = 0\n",
    "        URM_test_row = np.empty(0)\n",
    "        URM_test_col = np.empty(0)\n",
    "        URM_test_values = np.empty(0)\n",
    "        URM_train_row = np.empty(0)\n",
    "        URM_train_col = np.empty(0)\n",
    "        URM_train_values = np.empty(0)\n",
    "        for playlist in range(0,playlistsSize):\n",
    "            tracks = np.array(self.train[self.train['playlist_id']==playlist]['track_id'])\n",
    "            if cont < len(target_playlists) and playlist == target_playlists[cont]:\n",
    "                train = tracks[0:int(len(tracks)*train_perc)]\n",
    "                test = tracks[int(len(tracks)*train_perc):]\n",
    "                URM_train_row = np.append(URM_train_row, [playlist]*len(train))\n",
    "                URM_train_col = np.append(URM_train_col, train)\n",
    "                URM_train_values = np.append(URM_train_values, [1]*len(train))\n",
    "                URM_test_row = np.append(URM_test_row, [playlist]*len(test))\n",
    "                URM_test_col = np.append(URM_test_col, test)\n",
    "                URM_test_values = np.append(URM_test_values, [1]*len(test))\n",
    "                cont = cont + 1\n",
    "                self.tracks_inside_playlists_train[playlist] = train\n",
    "            else:\n",
    "                URM_train_row = np.append(URM_train_row, [playlist]*len(tracks))\n",
    "                URM_train_col = np.append(URM_train_col, tracks)\n",
    "                URM_train_values = np.append(URM_train_values, [1]*len(tracks))\n",
    "            \n",
    "\n",
    "\n",
    "        self.URM_train = sps.csr_matrix( (URM_train_values,(URM_train_row, URM_train_col)), shape=(playlistsSize, tracksSize))\n",
    "        self.URM_test = sps.csr_matrix( (URM_test_values,(URM_test_row, URM_test_col)), shape=(playlistsSize, tracksSize))\n",
    "\n",
    "        return self.URM_train, self.URM_test\n",
    "    \n",
    "    def get_tracks(self):\n",
    "        tracks = self.tracks['track_id'].unique()\n",
    "        return np.sort(tracks)\n",
    "    \n",
    "    def get_playlists(self):\n",
    "        playlists = self.train['playlist_id'].unique()\n",
    "        return np.sort(playlists)\n",
    "    \n",
    "    def get_target_playlists(self):\n",
    "        target_playlists = self.target_playlists['playlist_id'].unique()\n",
    "        return np.sort(target_playlists)\n",
    "    \n",
    "    def get_artists(self):\n",
    "        artists = self.tracks['artist_id'].unique()\n",
    "        return np.sort(artists)\n",
    "    \n",
    "    def get_albums(self):\n",
    "        albums = self.tracks['album_id'].unique()\n",
    "        return np.sort(albums)\n",
    "    \n",
    "    def get_durations(self):\n",
    "        durations = self.tracks['duration_sec'].unique()\n",
    "        return np.sort(durations)\n",
    "    \n",
    "    def get_target_playlist_index(self, target_playlist):\n",
    "        return np.where(self.playlists == target_playlist)[0][0] #DA RIVEDERE\n",
    "    \n",
    "    def get_URM(self):\n",
    "        grouped = self.train.groupby('playlist_id', as_index=True).apply(lambda x: list(x['track_id']))\n",
    "        self.URM = MultiLabelBinarizer(classes=self.get_tracks(), sparse_output=True).fit_transform(grouped)\n",
    "        return self.URM\n",
    "    \n",
    "    def get_URM_transpose(self):\n",
    "        grouped = self.train.groupby('track_id', as_index=True).apply(lambda x: list(x['playlist_id']))\n",
    "        self.URM = MultiLabelBinarizer(classes=self.get_playlists(), sparse_output=True).fit_transform(grouped)\n",
    "        return self.URM\n",
    "    \n",
    "    def get_ICM(self):\n",
    "        artists = self.tracks.reindex(columns=['track_id', 'artist_id'])\n",
    "        artists.sort_values(by='track_id', inplace=True)\n",
    "        artists_list = [[a] for a in artists['artist_id']]\n",
    "        icm_artists = MultiLabelBinarizer(classes=self.get_artists(), sparse_output=True).fit_transform(artists_list)\n",
    "        icm_artists_csr = icm_artists.tocsr()\n",
    "        #return icm_artists_csr\n",
    "        \n",
    "        albums = self.tracks.reindex(columns=['track_id', 'album_id'])\n",
    "        albums.sort_values(by='track_id', inplace=True)\n",
    "        albums_list = [[a] for a in albums['album_id']]\n",
    "        icm_albums = MultiLabelBinarizer(classes=self.get_albums(), sparse_output=True).fit_transform(albums_list)\n",
    "        icm_albums_csr = icm_albums.tocsr()\n",
    "        #return icm_albums_csr\n",
    "        \n",
    "        #durations= self.tracks.reindex(columns=['track_id', 'duration_sec'])\n",
    "        #durations.sort_values(by='track_id', inplace=True)\n",
    "        #durations_list = [[d] for d in durations['duration_sec']]\n",
    "        #icm_durations = MultiLabelBinarizer(classes=self.get_durations(), sparse_output=True).fit_transform(durations_list)\n",
    "        #icm_durations_csr= icm_durations.tocsr()\n",
    "        \n",
    "        return sparse.hstack((0.65*icm_artists_csr,icm_albums_csr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Builder()\n",
    "URM_train, URM_test = b.train_test_holdout( 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1220  8360 12844 14301 18397]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity column 20600 ( 100 % ), 2729.06 column/sec, elapsed time 0.13 min\n",
      "Similarity column 16300 ( 79 % ), 540.99 column/sec, elapsed time 0.50 min\n",
      "Similarity column 20600 ( 100 % ), 542.79 column/sec, elapsed time 0.63 min\n"
     ]
    }
   ],
   "source": [
    "recommender = ItemCBFKNNRecommender(URM_train, b.get_ICM())\n",
    "contentSimilarity = recommender.fit(shrink=0.0, topK=500)\n",
    "\n",
    "recommender = ItemCBFKNNRecommender(URM_train, b.get_URM_transpose())\n",
    "collaborativeSimilarity = recommender.fit(shrink=5.0, topK=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_function import evaluate_algorithm\n",
    "from Compute_Similarity_Python import Compute_Similarity_Python\n",
    "class ItemCBFKNNRecommender(object):\n",
    "    \n",
    "    def __init__(self, URM, ICM):\n",
    "        self.URM = URM\n",
    "        self.ICM = ICM\n",
    "    \n",
    "    \n",
    "    def fit(self, topK=50, shrink=100, normalize = True, similarity = \"cosine\"):\n",
    "        \n",
    "        similarity_object = Compute_Similarity_Python(self.ICM.T, shrink=shrink,\n",
    "        topK=topK, normalize=normalize,\n",
    "        similarity = similarity)\n",
    "\n",
    "        self.W_sparse = similarity_object.compute_similarity()\n",
    "\n",
    "        #print (self.W_sparse)\n",
    "        sparse.save_npz('cbsim.npz', self.W_sparse, compressed=True)\n",
    "        sparse_matrix = sparse.load_npz('cbsim.npz')\n",
    "        #print (sparse_matrix)\n",
    "        return self.W_sparse\n",
    "    \n",
    "    \n",
    "    def recommend(self, user_id, at=None, exclude_seen=True):\n",
    "        # compute the scores using the dot product\n",
    "        user_profile = self.URM[user_id]\n",
    "        scores = user_profile.dot(self.W_sparse).toarray().ravel()\n",
    "        \n",
    "        if exclude_seen:\n",
    "            scores = self.filter_seen(user_id, scores)\n",
    "        \n",
    "        # rank items\n",
    "        ranking = scores.argsort()[::-1]\n",
    "        \n",
    "        return ranking[:at]\n",
    "    \n",
    "    \n",
    "    def filter_seen(self, user_id, scores):\n",
    "        \n",
    "        start_pos = self.URM.indptr[user_id]\n",
    "        end_pos = self.URM.indptr[user_id+1]\n",
    "        \n",
    "        user_profile = self.URM.indices[start_pos:end_pos]\n",
    "        \n",
    "        scores[user_profile] = -np.inf\n",
    "        \n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class hybridRecommender():\n",
    "\n",
    "    def merge(self, a, b):\n",
    "        hybridMatrix = a*contentSimilarity + b*collaborativeSimilarity\n",
    "        return hybridMatrix\n",
    "\n",
    "    def __init__(self):\n",
    "        self.bestSimilarTracks = self.merge(0.10, 1.0)\n",
    "        #self.df = pd.read_csv('input/train.csv')\n",
    "        #df1 = pd.read_csv('target_playlists.csv')\n",
    "        #self.playlists = np.array(df1['playlist_id'])\n",
    "        #submission = np.empty((len(playlists),2), dtype=object)\n",
    "        self.cont = -1\n",
    "    \n",
    "    def recommend(self, playlist):\n",
    "        self.cont = self.cont + 1\n",
    "\n",
    "        tracks = b.get_tracks_inside_playlist_train(playlist)\n",
    "        #submission[cont][0] = playlist\n",
    "        tracksSet = set(tracks)\n",
    "        best = {}\n",
    "        temp = 1\n",
    "        for track in tracks:\n",
    "            row_start = self.bestSimilarTracks.indptr[track]\n",
    "            row_end = self.bestSimilarTracks.indptr[track+1]\n",
    "            similarTracks = self.bestSimilarTracks.indices[row_start:row_end]\n",
    "            similarityValues = self.bestSimilarTracks.data[row_start:row_end]\n",
    "            for i in range(0, len(similarTracks)):\n",
    "                if not similarTracks[i] in tracksSet:\n",
    "                    if similarTracks[i] in best:\n",
    "                        best[similarTracks[i]]=best[similarTracks[i]]-similarityValues[i]*temp\n",
    "                    else:\n",
    "                        best[similarTracks[i]]=-1*similarityValues[i]*temp\n",
    "            if self.cont < 5000:\n",
    "                temp -= 1/(len(tracks)+1)\n",
    "        preSorted = [[v, k] for k,v in best.items()]\n",
    "        best = np.empty((max(11,len(preSorted)), 2), dtype=object)\n",
    "        for i in range(len(preSorted)):\n",
    "            best[i] = preSorted[i]\n",
    "        if len(preSorted) < 11:\n",
    "            for i in range(len(preSorted), 11):\n",
    "                best[i] = [0, random.randint(0, 20000)]\n",
    "            print(best)\n",
    "        best = best[best[:,0].argpartition(10)][0:10]\n",
    "        best = best[best[:,0].argsort()][:,1]\n",
    "        return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recommend' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-270bfc02d2b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'recommend' is not defined"
     ]
    }
   ],
   "source": [
    "print(recommend(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "\n",
    "\n",
    "\n",
    "def precision(is_relevant, relevant_items):\n",
    "\n",
    "    #is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "\n",
    "    precision_score = np.sum(is_relevant, dtype=np.float32) / len(is_relevant)\n",
    "\n",
    "    return precision_score\n",
    "\n",
    "\n",
    "\n",
    "def recall(is_relevant, relevant_items):\n",
    "\n",
    "    #is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "\n",
    "    recall_score = np.sum(is_relevant, dtype=np.float32) / relevant_items.shape[0]\n",
    "\n",
    "    return recall_score\n",
    "\n",
    "\n",
    "\n",
    "def MAP(is_relevant, relevant_items):\n",
    "\n",
    "    #is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "\n",
    "    # Cumulative sum: precision at 1, at 2, at 3 ...\n",
    "    p_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(is_relevant.shape[0]))\n",
    "\n",
    "    map_score = np.sum(p_at_k) / np.min([relevant_items.shape[0], is_relevant.shape[0]])\n",
    "\n",
    "    return map_score\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_algorithm(URM_test, recommender_object, at=5):\n",
    "\n",
    "    cumulative_precision = 0.0\n",
    "    cumulative_recall = 0.0\n",
    "    cumulative_MAP = 0.0\n",
    "\n",
    "    num_eval = 0\n",
    "\n",
    "    URM_test = sps.csr_matrix(URM_test)\n",
    "\n",
    "    n_users = URM_test.shape[0]\n",
    "\n",
    "    ordered_target_playlists = b.get_ordered_target_playlists()\n",
    "    unordered_target_playlists = b.get_unordered_target_playlists()\n",
    "\n",
    "    for i in range(len(ordered_target_playlists)):\n",
    "        \n",
    "        user_id = ordered_target_playlists[i]\n",
    "\n",
    "        start_pos = URM_test.indptr[user_id]\n",
    "        end_pos = URM_test.indptr[user_id+1]\n",
    "\n",
    "        if end_pos-start_pos>0:\n",
    "\n",
    "            \n",
    "            relevant_items = URM_test.indices[start_pos:end_pos]\n",
    "\n",
    "            recommended_items = recommender_object.recommend(user_id)\n",
    "            \n",
    "            if i == 0:\n",
    "                print(user_id)\n",
    "                print(recommended_items)\n",
    "                print(relevant_items)\n",
    "            num_eval+=1\n",
    "\n",
    "            is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "\n",
    "            cumulative_precision += precision(is_relevant, relevant_items)\n",
    "            cumulative_recall += recall(is_relevant, relevant_items)\n",
    "            cumulative_MAP += MAP(is_relevant, relevant_items)\n",
    "            \n",
    "    print(\"ordered finished\")\n",
    "        \n",
    "    for i in range(len(unordered_target_playlists)):\n",
    "        \n",
    "        user_id = unordered_target_playlists[i]\n",
    "\n",
    "        start_pos = URM_test.indptr[user_id]\n",
    "        end_pos = URM_test.indptr[user_id+1]\n",
    "\n",
    "        if end_pos-start_pos>0:\n",
    "\n",
    "            \n",
    "                \n",
    "            relevant_items = URM_test.indices[start_pos:end_pos]\n",
    "\n",
    "            recommended_items = recommender_object.recommend(user_id)\n",
    "            \n",
    "            if i == 0:\n",
    "                print(user_id)\n",
    "                print(recommended_items)\n",
    "                print(relevant_items)\n",
    "            num_eval+=1\n",
    "\n",
    "            is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "\n",
    "            cumulative_precision += precision(is_relevant, relevant_items)\n",
    "            cumulative_recall += recall(is_relevant, relevant_items)\n",
    "            cumulative_MAP += MAP(is_relevant, relevant_items)\n",
    "\n",
    "\n",
    "    cumulative_precision /= num_eval\n",
    "    cumulative_recall /= num_eval\n",
    "    cumulative_MAP /= num_eval\n",
    "\n",
    "    print(\"Recommender performance is: Precision = {:.4f}, Recall = {:.4f}, MAP = {:.4f}\".format(\n",
    "        cumulative_precision, cumulative_recall, cumulative_MAP))\n",
    "\n",
    "    result_dict = {\n",
    "        \"precision\": cumulative_precision,\n",
    "        \"recall\": cumulative_recall,\n",
    "        \"MAP\": cumulative_MAP,\n",
    "    }\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[17154 13424 8749 10100 12311 11233 5924 4603 4189 14765]\n",
      "[  159  1775  7660 12493 13424 15740 17495]\n"
     ]
    }
   ],
   "source": [
    "evaluate_algorithm(URM_test, hybridRecommender(),at=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
